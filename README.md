# PrÃ©-processamento de Dados para LLM

Este projeto realiza o prÃ©-processamento completo de textos em portuguÃªs para preparaÃ§Ã£o de dados destinados a Large Language Models (LLM).

## ğŸ“‹ Funcionalidades

O sistema executa 13 etapas sequenciais de prÃ©-processamento:

1. **Remover tags HTML** - Remove tags e decodifica entidades HTML
2. **Remover URLs** - Remove links HTTP/HTTPS, www, e URLs encurtadas
3. **Remover emojis** - Remove emojis e sÃ­mbolos Unicode
4. **Remover stopwords** - Remove palavras irrelevantes em portuguÃªs
5. **Remover sinais de pontuaÃ§Ã£o** - Remove pontuaÃ§Ã£o mantendo letras e nÃºmeros
6. **Remover caracteres especiais** - Remove caracteres especiais (exceto acentos)
7. **Remover espaÃ§os excedentes** - Remove mÃºltiplos espaÃ§os e quebras de linha
8. **Substituir palavras de chat** - Normaliza abreviaÃ§Ãµes (vc â†’ vocÃª, pq â†’ porque)
9. **Converter nÃºmeros em palavras** - Transforma dÃ­gitos em texto (3 â†’ trÃªs)
10. **Converter para minÃºsculas** - Padroniza todo o texto em caixa baixa
11. **CorreÃ§Ã£o ortogrÃ¡fica** - Aplica correÃ§Ãµes bÃ¡sicas de ortografia
12. **StemizaÃ§Ã£o** - Reduz palavras ao seu radical
13. **LematizaÃ§Ã£o** - Reduz palavras Ã  sua forma canÃ´nica

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **NLTK** - Natural Language Toolkit para processamento de linguagem natural
- **TextBlob** - Biblioteca para processamento de texto
- **Inflect** - ConversÃ£o de nÃºmeros para palavras

## ğŸ“ Estrutura do Projeto

```
Pre-processamento-de-dados-para-LLM/
â”œâ”€â”€ preprocessamento_textos.py    # Script principal
â”œâ”€â”€ jornal.txt                    # Texto do jornal A Tribuna
â”œâ”€â”€ bula_doril.txt               # Bula do medicamento Doril
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ setup_venv.sh               # Script de configuraÃ§Ã£o do ambiente virtual
â”œâ”€â”€ venv/                       # Ambiente virtual Python
â”œâ”€â”€ jornal_processado.txt       # Resultado do prÃ©-processamento do jornal
â”œâ”€â”€ bula_processada.txt         # Resultado do prÃ©-processamento da bula
â””â”€â”€ README.md                   # Este arquivo

```

## ğŸš€ Como Usar



### OpÃ§Ã£o 2: ConfiguraÃ§Ã£o manual

```bash
# 1. Cria o ambiente virtual
python3 -m venv venv

# 2. Ativa o ambiente virtual
source venv/bin/activate

# 3. Instala as dependÃªncias
pip install -r requirements.txt

# 4. Executa o script
python preprocessamento_textos.py

# 5. Para desativar o ambiente virtual
deactivate
```

## ğŸ“Š Exemplo de ExecuÃ§Ã£o

O script processa dois textos distintos:

### Jornal A Tribuna
- **Texto original**: 2.634 caracteres
- **Texto processado**: 1.598 caracteres  
- **ReduÃ§Ã£o**: 39.3%

### Bula Doril
- **Texto original**: 13.742 caracteres
- **Texto processado**: 8.348 caracteres
- **ReduÃ§Ã£o**: 39.3%

## ğŸ“ˆ Resultados

ApÃ³s cada etapa, o sistema exibe:
- Tamanho do texto antes e depois
- Quantidade de caracteres removidos
- Amostra do resultado parcial
- EstatÃ­sticas de reduÃ§Ã£o total

## ğŸ¯ Casos de Uso

- PreparaÃ§Ã£o de dados para treinamento de LLMs
- Limpeza de textos para anÃ¡lise de sentimentos
- NormalizaÃ§Ã£o de conteÃºdo web
- Processamento de documentos mÃ©dicos
- AnÃ¡lise de conteÃºdo jornalÃ­stico

## ğŸ”§ PersonalizaÃ§Ã£o

Para adaptar o script aos seus dados:

1. **Substitua os arquivos de entrada**:
   - `jornal.txt` e `bula_doril.txt` pelos seus textos
   
2. **Modifique as stopwords**:
   - Edite `self.stop_words` na classe `TextPreprocessor`
   
3. **Ajuste palavras de chat**:
   - Modifique `self.chat_words` conforme necessÃ¡rio
   
4. **Configure correÃ§Ãµes ortogrÃ¡ficas**:
   - Atualize `_basic_portuguese_corrections()` com suas correÃ§Ãµes especÃ­ficas


## ğŸ“ Notas Importantes

- O script foi otimizado para textos em **portuguÃªs brasileiro**
- A stemizaÃ§Ã£o e lematizaÃ§Ã£o usam o algoritmo Snowball para portuguÃªs
- A correÃ§Ã£o ortogrÃ¡fica Ã© bÃ¡sica - para casos complexos, considere usar ferramentas especializadas
- Os arquivos processados sÃ£o salvos automaticamente no diretÃ³rio do projeto

